{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864afc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import cv2\n",
    "\n",
    "import pathlib\n",
    "\n",
    "Main_image = \"K:/LEGOs/Bricks/BRICKS_COLOR\" # zmienić !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "photo_path_gray = \"K:/LEGOs/Bricks/BRICKS_GRAY\" # zmienić !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir_Brick = Main_image\n",
    "data_dir_Gray = photo_path_gray\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a7e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 files belonging to 5 classes.\n",
      "Using 5120 files for training.\n",
      "Found 6400 files belonging to 5 classes.\n",
      "Using 1280 files for validation.\n",
      "['Black_Brick', 'Blue_Brick', 'Orange_Brick', 'Red_Brick', 'Yellow_Brick']\n",
      "Found 6400 files belonging to 5 classes.\n",
      "Using 5120 files for training.\n",
      "Found 6400 files belonging to 5 classes.\n",
      "Using 1280 files for validation.\n",
      "['2x1', '4x2', '6x1', 'Cylinder', 'Ring']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_ds_Brick = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_Brick,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds_Brick = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_Brick,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names_Brick = train_ds_Brick.class_names\n",
    "print(class_names_Brick)\n",
    "#----------------------------------------------------------------#\n",
    "train_ds_Gray = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_Gray,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds_Gray = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_Gray,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names_Gray = train_ds_Gray.class_names\n",
    "print(class_names_Gray)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97416495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.9603495\n",
      "0.22763109 0.8163168\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds_Brick = train_ds_Brick.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_Brick = val_ds_Brick.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer_Brick = layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds_Brick = train_ds_Brick.map(lambda x, y: (normalization_layer_Brick(x), y))\n",
    "image_batch_Brick, labels_batch_Brick = next(iter(normalized_ds_Brick))\n",
    "first_image_Brick = image_batch_Brick[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image_Brick), np.max(first_image_Brick))\n",
    "#----------------------------------------------------------------#\n",
    "train_ds_Gray = train_ds_Gray.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_Gray = val_ds_Gray.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer_Gray = layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds_Gray = train_ds_Gray.map(lambda x, y: (normalization_layer_Gray(x), y))\n",
    "image_batch_Gray, labels_batch_Gray = next(iter(normalized_ds_Gray))\n",
    "first_image_Gray = image_batch_Gray[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image_Gray), np.max(first_image_Gray))\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba51262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 1024), dtype=tf.float32, name=None), name='mobilenet_1.00_224/conv_pw_13_relu/Relu6:0', description=\"created by layer 'mobilenet_1.00_224'\")\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "num_classes_Brick = len(class_names_Brick)\n",
    "\n",
    "input_shape_Brick = (224,224,3)\n",
    "\n",
    "base_model_Brick = MobileNet(input_shape_Brick,include_top=False, weights='imagenet')\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "base_model_Brick.trainable = False\n",
    "\n",
    "inputs_Brick = tf.keras.Input(shape = input_shape_Brick)\n",
    "x_Brick = preprocess_input(inputs_Brick)\n",
    "x_Brick = layers.Normalization()(x_Brick)\n",
    "print(x_Brick)\n",
    "#x = layers.Rescaling(1./255, input_shape=(img_height, img_width, 3))\n",
    "x = base_model_Brick(x_Brick, training = False)\n",
    "print(x_Brick)\n",
    "#----------------------------------------------------------------#\n",
    "num_classes_Gray = len(class_names_Gray)\n",
    "\n",
    "input_shape_Gray = (224,224,3)\n",
    "\n",
    "base_model_Gray = MobileNet(input_shape_Gray,include_top=False, weights='imagenet')\n",
    "\n",
    "preprocess_input_Gray = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "base_model_Gray.trainable = False\n",
    "\n",
    "inputs_Gray = tf.keras.Input(shape = input_shape_Gray)\n",
    "x_Gray = preprocess_input_Gray(inputs_Gray)\n",
    "x_Gray = layers.Normalization()(x_Gray)\n",
    "print(x_Gray)\n",
    "#x = layers.Rescaling(1./255, input_shape=(img_height, img_width, 3))\n",
    "x_Gray = base_model_Gray(x_Gray, training = False)\n",
    "print(x_Gray)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db45e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 16), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 16), dtype=tf.float32, name=None), name='dropout_3/Identity:0', description=\"created by layer 'dropout_3'\")\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "x_Brick = layers.Conv2D(16, 3, padding='same', activation='relu')(x_Brick)\n",
    "x_Brick = layers.Dropout(0.2)(x_Brick) # for increasing accuracy !!!! <== Important!!!!\n",
    "\n",
    "#x = layers.GlobalAveragePooling2D()(x)\n",
    "print(x_Brick)\n",
    "x_Brick = layers.Conv2D(32, 3, padding='same', activation='relu')(x_Brick)\n",
    "x_Brick = layers.Dropout(0.2)(x_Brick) # for increasing accuracy !!!! <== Important!!!!\n",
    "#x = layers.GlobalAveragePooling2D()(x)\n",
    "x_Brick = layers.Conv2D(64, 3, padding='same', activation='relu')(x_Brick)\n",
    "x_Brick = layers.Dropout(0.2)(x_Brick) # for increasing accuracy !!!! <== Important!!!!\n",
    "\n",
    "x_Brick = layers.GlobalAveragePooling2D()(x_Brick)\n",
    "x_Brick = layers.Flatten()(x_Brick)\n",
    "x_Brick = layers.Dense(128, activation='relu')(x_Brick)\n",
    "output_Brick = layers.Dense(num_classes_Brick, activation = 'softmax')(x_Brick)\n",
    "\n",
    "model_Brick = tf.keras.Model(inputs_Brick, output_Brick )\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "x_Gray = layers.Conv2D(16, 3, padding='same', activation='relu')(x_Gray)\n",
    "x_Gray = layers.Dropout(0.1)(x_Gray) # for increasing accuracy !!!! <== Important!!!!\n",
    "\n",
    "#x = layers.GlobalAveragePooling2D()(x)\n",
    "print(x_Gray)\n",
    "x_Gray = layers.Conv2D(32, 3, padding='same', activation='relu')(x_Gray)\n",
    "x_Gray = layers.Dropout(0.1)(x_Gray) # for increasing accuracy !!!! <== Important!!!!\n",
    "#x = layers.GlobalAveragePooling2D()(x)\n",
    "x_Gray = layers.Conv2D(64, 3, padding='same', activation='relu')(x_Gray)\n",
    "x_Gray = layers.Dropout(0.1)(x_Gray) # for increasing accuracy !!!! <== Important!!!!\n",
    "\n",
    "x_Gray = layers.GlobalAveragePooling2D()(x_Gray)\n",
    "x_Gray = layers.Flatten()(x_Gray)\n",
    "x_Gray = layers.Dense(128, activation='relu')(x_Gray)\n",
    "output_Gray = layers.Dense(num_classes_Gray, activation = 'softmax')(x_Gray)\n",
    "\n",
    "model_Gray = tf.keras.Model(inputs_Gray, output_Gray )\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e460eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 224, 224, 3)      7         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 16)      448       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 224, 224, 16)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 32)      4640      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 64)      18496     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,556\n",
      "Trainable params: 32,549\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLam  (None, 224, 224, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " normalization_1 (Normalizat  (None, 224, 224, 3)      7         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 16)          147472    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 7, 16)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,408,444\n",
      "Trainable params: 179,573\n",
      "Non-trainable params: 3,228,871\n",
      "_________________________________________________________________\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda\\envs\\ml\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.001\n",
    "model_Brick.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_Brick.summary()\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "model_Gray.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_Gray.summary()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "856bc449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda\\envs\\ml\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 437s 3s/step - loss: 0.7303 - accuracy: 0.6777 - val_loss: 0.2044 - val_accuracy: 0.9289\n",
      "160/160 [==============================] - 77s 466ms/step - loss: 0.1416 - accuracy: 0.9494 - val_loss: 0.0117 - val_accuracy: 0.9953\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "epochs_Brick=1\n",
    "history_Brick = model_Brick.fit(\n",
    "  train_ds_Brick,\n",
    "  validation_data=val_ds_Brick,\n",
    "  epochs=epochs_Brick\n",
    ")\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "epochs_Gray=1\n",
    "history_Gray = model_Gray.fit(\n",
    "  train_ds_Gray,\n",
    "  validation_data=val_ds_Gray,\n",
    "  epochs=epochs_Gray\n",
    ")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_Brick = history_Brick.history['accuracy_Brick']\n",
    "val_acc_Brick = history_Brick.history['val_accuracy_Brick']\n",
    "\n",
    "loss_Brick = history_Brick.history['loss_Brick']\n",
    "val_loss_Brick = history_Brick.history['val_loss_Brick']\n",
    "\n",
    "epochs_range_Brick = range(epochs_Brick)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_Brick, acc_Brick, label='Training Accuracy_Brick')\n",
    "plt.plot(epochs_range_Brick, val_acc_Brick, label='Validation Accuracy_Brick')\n",
    "plt.legend(loc='lower right_Brick')\n",
    "plt.title('Training and Validation Accuracy_Brick')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_Brick, loss_Brick, label='Training Loss_Brick')\n",
    "plt.plot(epochs_range_Brick, val_loss_Brick, label='Validation Loss_Brick')\n",
    "plt.legend(loc='upper right_Brick')\n",
    "plt.title('Training and Validation Loss_Brick')\n",
    "plt.show()\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "acc_Gray = history_Gray.history['accuracy']\n",
    "val_acc_Gray = history_Gray.history['val_accuracy']\n",
    "\n",
    "loss_Gray = history_Gray.history['loss']\n",
    "val_loss_Gray = history_Gray.history['val_loss']\n",
    "\n",
    "epochs_range_Gray = range(epochs_Gray)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range_Gray, acc_Gray, label='Training Accuracy')\n",
    "plt.plot(epochs_range_Gray, val_acc_Gray, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range_Gray, loss_Gray, label='Training Loss')\n",
    "plt.plot(epochs_range_Gray, val_loss_Gray, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe24bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_Brick\n",
      "saved_Gray\n"
     ]
    }
   ],
   "source": [
    "model_Brick.save('lego_classifier_Brick_Mobile_Shape_dropout10.keras')\n",
    "\n",
    "print('saved_Brick')\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "model_Gray.save('lego_classifier_Gray_Mobile.keras')\n",
    "\n",
    "print('saved_Gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f274277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_Brick = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images_Brick, _ in train_ds_Brick.take(1):\n",
    "  for i_Brick in range(9):\n",
    "    augmented_images_Brick = data_augmentation_Brick(images_Brick)\n",
    "    ax = plt.subplot(3, 3, i_Brick + 1)\n",
    "    plt.imshow(augmented_images_Brick[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "data_augmentation_Gray = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images_Gray, _ in train_ds_Gray.take(1):\n",
    "  for i_Gray in range(9):\n",
    "    augmented_images_Gray = data_augmentation_Gray(images_Gray)\n",
    "    ax_Gray = plt.subplot(3, 3, i_Gray + 1)\n",
    "    plt.imshow(augmented_images_Gray[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac680e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# brick_path = \"C:/Users/krzys/Downloads/red.jpg\"\n",
    "\n",
    "# img = tf.keras.utils.load_img(\n",
    "#     brick_path, target_size=(img_height, img_width)\n",
    "# )\n",
    "# img_array = tf.keras.utils.img_to_array(img)\n",
    "# img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "# predictions = model.predict(img_array)\n",
    "# score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "# print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "393e8ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 749ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 1s 568ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.96 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "This image most likely belongs to 6x1 with a 99.81 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.15 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "This image most likely belongs to 6x1 with a 96.39 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "This image most likely belongs to 6x1 with a 99.87 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "This image most likely belongs to 6x1 with a 99.98 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "This image most likely belongs to 6x1 with a 99.99 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 99.99 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.33 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "This image most likely belongs to 6x1 with a 98.21 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Red_Brick with a 85.46 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "This image most likely belongs to 2x1 with a 65.48 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.44 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "This image most likely belongs to 6x1 with a 95.58 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 99.62 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.93 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "This image most likely belongs to 6x1 with a 99.30 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "This image most likely belongs to 6x1 with a 99.99 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.96 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.99 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.66 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 95.89 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Red_Brick with a 93.75 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 74.11 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "This image most likely belongs to Red_Brick with a 47.97 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 4x2 with a 53.88 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "This image most likely belongs to 6x1 with a 99.97 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 99.84 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Blue_Brick with a 31.38 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 4x2 with a 54.49 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Orange_Brick with a 22.37 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "This image most likely belongs to 2x1 with a 45.64 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.38 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 4x2 with a 99.12 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Blue_Brick with a 49.18 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 4x2 with a 92.96 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.84 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "This image most likely belongs to 4x2 with a 99.33 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Blue_Brick with a 98.94 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "This image most likely belongs to 4x2 with a 73.20 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "This image most likely belongs to Blue_Brick with a 93.90 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "This image most likely belongs to 4x2 with a 99.47 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "This image most likely belongs to Red_Brick with a 97.15 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.65 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.31 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "This image most likely belongs to 4x2 with a 99.24 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "This image most likely belongs to Red_Brick with a 42.96 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "This image most likely belongs to 2x1 with a 36.47 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.88 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.61 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "This image most likely belongs to Red_Brick with a 59.32 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "This image most likely belongs to 2x1 with a 69.30 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "This image most likely belongs to Red_Brick with a 85.39 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "This image most likely belongs to 2x1 with a 66.87 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "This image most likely belongs to Red_Brick with a 97.21 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 65.50 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "This image most likely belongs to Red_Brick with a 97.88 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "This image most likely belongs to 6x1 with a 72.74 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Red_Brick with a 88.46 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "This image most likely belongs to 2x1 with a 51.08 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.73 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 95.80 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Red_Brick with a 100.00 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 100.00 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.98 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 99.95 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "This image most likely belongs to 6x1 with a 99.78 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.88 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "This image most likely belongs to 6x1 with a 99.90 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.89 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 6x1 with a 99.87 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Red_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 6x1 with a 99.96 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Black_Brick with a 27.70 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to Cylinder with a 39.57 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Black_Brick with a 29.77 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "This image most likely belongs to Cylinder with a 39.84 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.96 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 4x2 with a 98.46 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.96 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "This image most likely belongs to 4x2 with a 99.32 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 4x2 with a 99.24 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.97 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "This image most likely belongs to 4x2 with a 99.08 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.97 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "This image most likely belongs to 4x2 with a 99.59 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.98 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to 4x2 with a 99.15 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.99 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 4x2 with a 98.72 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Blue_Brick with a 99.71 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to 4x2 with a 97.09 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "This image most likely belongs to Blue_Brick with a 34.01 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "This image most likely belongs to 2x1 with a 33.45 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Blue_Brick with a 43.27 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "This image most likely belongs to Cylinder with a 49.68 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "This image most likely belongs to Blue_Brick with a 41.40 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "This image most likely belongs to Cylinder with a 56.09 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "This image most likely belongs to Red_Brick with a 30.76 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "This image most likely belongs to Cylinder with a 44.21 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "This image most likely belongs to Red_Brick with a 27.15 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "This image most likely belongs to Cylinder with a 44.76 percent confidence.\n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "This image most likely belongs to Red_Brick with a 27.70 percent confidence.\n",
      "done changing to gray\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "This image most likely belongs to Cylinder with a 41.56 percent confidence.\n",
      "-----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m img_array_Brick \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimg_to_array(img_Brick)\n\u001b[0;32m     40\u001b[0m img_array_Brick \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array_Brick, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Create a batch\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m predictions_Brick \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_Brick_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array_Brick\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m score_Brick \u001b[38;5;241m=\u001b[39m predictions_Brick[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis image most likely belongs to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with a \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m percent confidence.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(class_names_Brick[np\u001b[38;5;241m.\u001b[39margmax(score_Brick)], \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(score_Brick))\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py:2249\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2247\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2248\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\keras\\engine\\data_adapter.py:1307\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1307\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[1;32m--> 721\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mK:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3407\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3408\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3409\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3411\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model_Brick_model = tf.keras.models.load_model('lego_classifier_Brick_Mobile_Shape_dropout10.keras')\n",
    "#model_Gray_model = tf.keras.models.load_model('lego_classifier_Gray_Mobile.keras')\n",
    "\n",
    "model_Brick_model = tf.keras.models.load_model('lego_classifier_Mobile.keras')\n",
    "model_Gray_model = tf.keras.models.load_model('lego_classifier_Mobile_Shape_dropout10.keras')\n",
    "\n",
    "\n",
    "\n",
    "test_photo_normal = \"C:/Users/krzys/Desktop/frames/frame1.png\"\n",
    "gray_path_save = \"K:/LEGOs/Bricks/gray.png\"\n",
    "brick_path = test_photo_normal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    result, img_Brick = cam.read() #grab frame from webcam\n",
    "     \n",
    "    cv2.imwrite(test_photo_normal, img_Brick) #save frame on the test_photo_normal path from cv2 format to png\n",
    "    \n",
    "    img_Brick = tf.keras.utils.load_img(\n",
    "    test_photo_normal, target_size=(img_height, img_width)\n",
    "    )  #load frame from the test_photo_normal path in tf format\n",
    "    img_array_Brick = tf.keras.utils.img_to_array(img_Brick)\n",
    "    img_array_Brick = tf.expand_dims(img_array_Brick, 0) # Create a batch\n",
    "\n",
    "    predictions_Brick = model_Brick_model.predict(img_array_Brick)\n",
    "    score_Brick = predictions_Brick[0]\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names_Brick[np.argmax(score_Brick)], 100 * np.max(score_Brick))\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    image_gray = cv2.imread(test_photo_normal) #load frame from the same test_photo_normal path in cv2 format\n",
    "    grayscale = cv2.cvtColor(image_gray, cv2.COLOR_BGR2GRAY) #change into grayscale\n",
    "    cv2.imwrite(gray_path_save, grayscale) #save grayscale frame on the gray_path_save path\n",
    "    print(\"done changing to gray\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    img_Gray = tf.keras.utils.load_img(\n",
    "        gray_path_save, target_size=(img_height, img_width)\n",
    "    ) #load grayscale frame from the same test_photo_normal path in tf format\n",
    "    img_array_Gray = tf.keras.utils.img_to_array(img_Gray)\n",
    "    img_array_Gray = tf.expand_dims(img_array_Gray, 0) # Create a batch\n",
    "\n",
    "    predictions_Gray = model_Gray_model.predict(img_array_Gray)\n",
    "    score_Gray = predictions_Gray[0]\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names_Gray[np.argmax(score_Gray)], 100 * np.max(score_Gray))\n",
    "        )\n",
    "    print(\n",
    "            \"-----------------------------------\"\n",
    "            \n",
    "        )\n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c17be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    result, image = cam.read()\n",
    "     \n",
    "    cv2.imwrite(photo_path, image)\n",
    "    \n",
    "    img = tf.keras.utils.load_img(brick_path, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) \n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))  \n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
